{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Behnam9473/AI/blob/main/custom_fuction_calling_1403_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAlJ4HmPf2yK"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertForQuestionAnswering, AutoTokenizer,BertForSequenceClassification\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')  # This mounts your Drive to a local directory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-rESHEUkfXe",
        "outputId": "17e97149-6919-45b0-e1a1-f3252db1fdd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/Nojan/ND/MVP/db_entity.xlsx'\n",
        "df = pd.read_excel(file_path)"
      ],
      "metadata": {
        "id": "VzMyQjD7ktey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmIhyYauk2AI",
        "outputId": "5022151d-6c63-4eff-f65d-4bf1378f3c01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                     question       intent      entities  \\\n",
            "0                 مقدار فروش دیروز چقدر بوده؟  fetch_sales    time_range   \n",
            "1       چه تعداد از محصولات امروز فروخته شده؟  fetch_sales    time_range   \n",
            "2       چه تعداد از محصولات امروز فروخته اند؟  fetch_sales    time_range   \n",
            "3      چه محصولاتی بیشترین فروش را داشته‌اند؟  fetch_sales  product_name   \n",
            "4   چه محصولی کمترین فروش را امروز داشته است؟  fetch_sales  product_name   \n",
            "\n",
            "       value  \n",
            "0  1 day ago  \n",
            "1      today  \n",
            "2      today  \n",
            "3  max_sales  \n",
            "4  min_sales  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path =\"/content/drive/MyDrive/my_qa_model\"\n",
        "model = BertForQuestionAnswering.from_pretrained(model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "wp4s0rwalHoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(df, test_size=0.2)\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.25)"
      ],
      "metadata": {
        "id": "oOLzZMYjmp-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_data(texts, labels):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in texts:\n",
        "        encoded_data = tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            return_attention_mask=True,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=128,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids.append(encoded_data['input_ids'])\n",
        "        attention_masks.append(encoded_data['attention_mask'])\n",
        "\n",
        "    return torch.cat(input_ids, dim=0), torch.cat(attention_masks, dim=0), torch.tensor(labels)"
      ],
      "metadata": {
        "id": "WO7YaeqhmtUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intent_labels = df['intent'].unique()\n",
        "intent_label_map = {label: idx for idx, label in enumerate(intent_labels)}\n",
        "# df['intent_label'] = df['intent'].map(intent_label_map)\n"
      ],
      "metadata": {
        "id": "aVCXgL2jm8YE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(intent_label_map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_d2UZyuXrXXD",
        "outputId": "0454f450-29c1-464b-85a5-050ec2fb2274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_inputs, train_masks, train_labels = encode_data(train_df['question'], [intent_labels[i] for i in train_df['intent']])\n",
        "# val_inputs, val_masks, val_labels = encode_data(val_df['question'], [intent_labels[i] for i in val_df['intent']])\n",
        "# test_inputs, test_masks, test_labels = encode_data(test_df['question'], [intent_labels[i] for i in test_df['intent']])\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Wg1wZTzKnJ9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change how train_labels, val_labels, and test_labels are generated\n",
        "train_labels = [intent_label_map[intent] for intent in train_df['intent']] # Use intent_label_map for mapping\n",
        "val_labels = [intent_label_map[intent] for intent in val_df['intent']]    # Use intent_label_map for mapping\n",
        "test_labels = [intent_label_map[intent] for intent in test_df['intent']]   # Use intent_label_map for mapping\n",
        "\n",
        "# Now call encode_data with the corrected labels\n",
        "train_inputs, train_masks, train_labels = encode_data(train_df['question'], train_labels)\n",
        "val_inputs, val_masks, val_labels = encode_data(val_df['question'], val_labels)\n",
        "test_inputs, test_masks, test_labels = encode_data(test_df['question'], test_labels)"
      ],
      "metadata": {
        "id": "HDgvoN3xn4AN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UlBgOPcyszJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=2)\n",
        "model = BertForSequenceClassification.from_pretrained(model_path, num_labels=len(intent_label_map))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvSwjly2n8h8",
        "outputId": "5ae4e539-3b62-4616-ec10-8418f9c82fb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/my_qa_model and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# مرحله 5: تنظیم مدل برای GPU در صورت موجود بودن\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# مرحله 6: تعریف optimizer و loss function\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# مرحله 7: آموزش مدل (Training loop)\n",
        "epochs = 10\n",
        "batch_size = 16"
      ],
      "metadata": {
        "id": "c4JJ5ENCoZ1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for i in range(0, len(train_inputs), batch_size):\n",
        "        input_batch = train_inputs[i:i+batch_size].to(device)\n",
        "        mask_batch = train_masks[i:i+batch_size].to(device)\n",
        "        label_batch = train_labels[i:i+batch_size].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        outputs = model(input_batch, attention_mask=mask_batch, labels=label_batch)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {total_loss/len(train_inputs)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNUIl5uioguf",
        "outputId": "5fea5aad-d2f9-43e5-dec4-8b4aee598d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.11827328841980189\n",
            "Epoch 2/10 | Loss: 0.044879818411722575\n",
            "Epoch 3/10 | Loss: 0.02450189440081653\n",
            "Epoch 4/10 | Loss: 0.010961495050692667\n",
            "Epoch 5/10 | Loss: 0.007263494995699081\n",
            "Epoch 6/10 | Loss: 0.007147983856261048\n",
            "Epoch 7/10 | Loss: 0.0068528653126737294\n",
            "Epoch 8/10 | Loss: 0.004791278128414393\n",
            "Epoch 9/10 | Loss: 0.004790461333000769\n",
            "Epoch 10/10 | Loss: 0.008424636597434679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6Z3iSQTonhv",
        "outputId": "d9601b72-da1e-40dd-b374-f899f9ebaca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=11, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# مرحله 8: ارزیابی مدل روی داده‌های تست\n",
        "with torch.no_grad():\n",
        "    for i in range(0, len(test_inputs), batch_size):\n",
        "        input_batch = test_inputs[i:i+batch_size].to(device)\n",
        "        mask_batch = test_masks[i:i+batch_size].to(device)\n",
        "\n",
        "        outputs = model(input_batch, attention_mask=mask_batch)\n",
        "        preds = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "        # نمایش پیش‌بینی‌ها\n",
        "        print(f\"Predictions: {preds}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj5Q0Vy8omBp",
        "outputId": "4b92af61-9c3a-4898-a528-6aa984a9a7cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: tensor([7, 4, 3, 1, 1, 0, 5, 5, 8, 2, 5, 0, 2, 3, 7, 2], device='cuda:0')\n",
            "Predictions: tensor([ 3,  1, 10,  5,  5,  3,  0,  4,  4, 10,  3,  5,  3,  4,  3,  3],\n",
            "       device='cuda:0')\n",
            "Predictions: tensor([ 3, 10,  2,  3, 10,  5,  0,  6,  5,  2,  9,  1,  0,  6,  0,  1],\n",
            "       device='cuda:0')\n",
            "Predictions: tensor([ 5,  4,  6,  4,  2,  0,  2,  9,  2,  2,  3,  0,  0,  7, 10, 10],\n",
            "       device='cuda:0')\n",
            "Predictions: tensor([ 4,  0,  2,  3,  0,  0,  0, 10,  9,  4,  1,  0,  3,  3,  1,  4],\n",
            "       device='cuda:0')\n",
            "Predictions: tensor([ 6, 10,  2,  0,  1,  2,  0,  3,  6,  0,  7,  4,  5,  0,  7,  5],\n",
            "       device='cuda:0')\n",
            "Predictions: tensor([10,  3,  3,  1,  7,  3,  3,  0,  0,  8,  3,  1,  3,  0,  4,  0],\n",
            "       device='cuda:0')\n",
            "Predictions: tensor([ 0,  0,  1,  0,  3,  2,  1,  2,  1,  4,  7,  7,  3,  0, 10,  6],\n",
            "       device='cuda:0')\n",
            "Predictions: tensor([0, 0, 3, 8, 7, 1, 7, 4, 5, 3, 3, 8, 4, 4, 0, 3], device='cuda:0')\n",
            "Predictions: tensor([5, 6, 3], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ذخیره مدل و tokenizer\n",
        "model.save_pretrained('./my_model_function_calling_v0.0.1')\n",
        "tokenizer.save_pretrained('./my_model_function_calling_v0.0.1')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CF_BLQSqYia",
        "outputId": "06a2264b-ebdd-45bd-85d4-49165eec34f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./my_model_function_calling_v0.0.1/tokenizer_config.json',\n",
              " './my_model_function_calling_v0.0.1/special_tokens_map.json',\n",
              " './my_model_function_calling_v0.0.1/vocab.txt',\n",
              " './my_model_function_calling_v0.0.1/added_tokens.json',\n",
              " './my_model_function_calling_v0.0.1/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {\n",
        "    'fetch_sales': 0,\n",
        "    'fetch_inventory': 1,\n",
        "    'fetch_orders': 2,\n",
        "    'fetch_best_selling_product': 3,\n",
        "    'fetch_total_revenue': 4,\n",
        "    'fetch_product_sales_count': 5,\n",
        "    'fetch_customers': 6,\n",
        "    'fetch_revenue': 7,\n",
        "    'fetch_delivery': 8,\n",
        "    'fetch_low_stock': 9,\n",
        "    'fetch_profit': 10\n",
        "}"
      ],
      "metadata": {
        "id": "4nnPZUBCrplc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# بارگذاری مدل ذخیره شده\n",
        "model_path = './my_model_function_calling_v0.0.1'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "model = BertForSequenceClassification.from_pretrained(model_path, num_labels=11)\n",
        "\n",
        "# تنظیم مدل برای استفاده از GPU در صورت موجود بودن\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vKvNWCSXqn2Q",
        "outputId": "50c65167-840e-4be9-d697-715e8f807ca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=11, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# لیست پرامپت‌ها برای تست\n",
        "prompts = [\n",
        "    \"سود امروز چقدر بوده است؟\",\n",
        "    \"کدام محصولات به زودی تمام می‌شوند؟\",\n",
        "    \"چه تعداد سفارشات امروز دریافت شده است؟\",\n",
        "    \"کدام محصول بیشترین فروش را داشته است؟\",\n",
        "    \"درآمد کل این ماه چقدر بوده است؟\"\n",
        "]\n",
        "\n",
        "# پیش‌بینی intent\n",
        "model.eval()  # تنظیم مدل به حالت ارزیابی\n",
        "for prompt in prompts:\n",
        "    # توکنایز کردن ورودی\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # پیش‌بینی خروجی مدل\n",
        "        outputs = model(**inputs)\n",
        "        predicted_label = torch.argmax(outputs.logits, dim=1).item()\n",
        "\n",
        "    # یافتن نام intent بر اساس label_map\n",
        "    intent = [key for key, value in label_map.items() if value == predicted_label][0]\n",
        "\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(f\"Predicted Intent: {intent}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA9KDNkyqvZI",
        "outputId": "ba006140-fb3c-44f2-b85a-b1feabd94017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: سود امروز چقدر بوده است؟\n",
            "Predicted Intent: fetch_profit\n",
            "\n",
            "Prompt: کدام محصولات به زودی تمام می‌شوند؟\n",
            "Predicted Intent: fetch_sales\n",
            "\n",
            "Prompt: چه تعداد سفارشات امروز دریافت شده است؟\n",
            "Predicted Intent: fetch_orders\n",
            "\n",
            "Prompt: کدام محصول بیشترین فروش را داشته است؟\n",
            "Predicted Intent: fetch_sales\n",
            "\n",
            "Prompt: درآمد کل این ماه چقدر بوده است؟\n",
            "Predicted Intent: fetch_revenue\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "12pKbzWQIYOZ0xMNFkVR5MfSwG2vtuS3p",
      "authorship_tag": "ABX9TyOJ1Z/jZkn4mFL6bYhEARcc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}